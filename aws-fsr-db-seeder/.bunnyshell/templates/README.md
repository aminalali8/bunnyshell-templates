# Installing AWS CSI Driver & Volume Snapshotter on Bunnyshell 
---- 

## Template Usage: 
Please check the pre-requisites section below before deploying the template, and fill in the template variables defined.

## Pre-requisites: 
> [!NOTE]
> Important: If you intend to use the Volume Snapshot feature, the Kubernetes Volume Snapshot CRDs must be installed before the EBS CSI driver. For installation instructions, see CSI Snapshotter Usage.


## Installation 
### CSI Snapshotter installation 
This is required if you will be using the `snapshot` feature and it must be installed before installing the aws csi driver.

```
EXSNAP_VERSION=7.0.2
kubectl apply -k "github.com/kubernetes-csi/external-snapshotter/client/config/crd?ref=v$EXSNAP_VERSION"
kubectl apply -k "github.com/kubernetes-csi/external-snapshotter/deploy/kubernetes/snapshot-controller?ref=v$EXSNAP_VERSION"
```

[Reference files here](https://github.com/kubernetes-csi/external-snapshotter/tree/master/client/config/crd).

### AWS IAMSERVICEACCOUNT for EBS CSI Driver

- [ ] Driver requires IAM permissions to talk to Amazon EBS to manage the volume on user's behalf.
    - [IAM Role for csi driver](https://docs.aws.amazon.com/eks/latest/userguide/csi-iam-role.html)
    ```
    # If you are not using aws eks ctl check the aws console or cli method 
    # Run the following command if you used eks ctl to setup your cluster
    eksctl create iamserviceaccount \
        --name ebs-csi-controller-sa \
        --namespace kube-system \
        --cluster <NAME OF YOUR CLUSTER> \
        --role-name AmazonEKS_EBS_CSI_DriverRole \
        --role-only \
        --attach-policy-arn arn:aws:iam::aws:policy/service-role/AmazonEBSCSIDriverPolicy \
        --approve
    ```

   - Managed Policy: `arn:aws:iam::aws:policy/service-role/AmazonEBSCSIDriverPolicy`
   - [Policy Example](https://github.com/kubernetes-sigs/aws-ebs-csi-driver/blob/master/docs/example-iam-policy.json) (See References: IAM Pollicy)

### AWS EBS CSI Driver

For reference [link](https://github.com/kubernetes-sigs/aws-ebs-csi-driver/blob/master/docs/install.md)

- [ ] Install the aws-csi-driver *(update `--service-account-role-arn` to the correct arn generated by creating the relevant iamserviceaccount)*  
    ```bash
    # eks ctl command
    eksctl create addon --name aws-ebs-csi-driver --cluster <NAME OF YOUR CLUSTER> --service-account-role-arn arn:aws:iam::123412341234:role/AmazonEKS_EBS_CSI_DriverRole --force
    ```
    ```bash
    # aws-cli command
    aws eks create-addon --cluster-name <NAME OF YOUR CLUSTER> --addon-name aws-ebs-csi-driver \
  --service-account-role-arn arn:aws:iam::123412341234:role/AmazonEKS_EBS_CSI_DriverRole
    ```

- [ ] Install using helm:
    ```
    # add repo source and update
    helm repo add aws-ebs-csi-driver https://kubernetes-sigs.github.io/aws-ebs-csi-driver
    helm repo update

    # generate values.yaml file and configure
    helm show value aws-ebs-csi-driver/aws-ebs-csi-driver > aws-ebs-csi-driver-values.yaml

    # NOTICE PLEASE EDIT THE VALUES FILE AND CONFIGURE THE CSI DRIVER AS THERE ARE PARAMETERS THAT ARE REQUIRED SUCH AS THE IAMSERVICEACCOUNT ARN.
    helm upgrade --install aws-ebs-csi-driver \
        --namespace kube-system \
        -f aws-ebs-csi-driver-values.yaml
        aws-ebs-csi-driver/aws-ebs-csi-driver
    ```

## Fast Snapshot Restore Setup 
### Pre-requisites:
- Install the Kubernetes Volume Snapshot CRDs and external-snapshotter sidecar.
- The EBS CSI Driver must be given permission to access the EnableFastSnapshotRestores EC2 API
```
{
  "Effect": "Allow",
  "Action": [
    "ec2:EnableFastSnapshotRestores"
  ],
  "Resource": "*"
}
```

### Generate Volume Snapshot Class & Enable FSR Restores
- Add the following parameter defined in the example VolumeSnapshotClass to enable FSR: 
```
apiVersion: snapshot.storage.k8s.io/v1
kind: VolumeSnapshotClass
metadata:
  name: ebs-vsc
driver: ebs.csi.aws.com
deletionPolicy: Delete
parameters:
  fastSnapshotRestoreAvailabilityZones: "eu-west-1a, eu-west-1b" # update this to the regions that have FSR Enabled
```

### Deploying on bunnyshell
Once the setup is complete you will need to create a snapshot of a volume that contains the mysql data files. 
After the snapshot is taken navigate to AWS EC2 Snapshots and configure the newly created snapshot to enable FastSnapshotRestore and choose the Availability Zones you will be using. 

> [!NOTE]
> Make sure you enclude the zones defined under parameters in the VolumeSnapshotClass Yaml defined above.

Copy the Snapshot ID for later. 

#### Example bunnyshell environment: 
Adjust the generated yaml file accordingly, edit the marked components where needed. Note that in the example below the template variables have been ommitted.

```
kind: Environment
name: Template-FSR-DB-Seeder  #<-- Update this name to your liking
type: primary
components:
    -
        kind: KubernetesManifest
        name: volume-snapshot-generator
        gitBranch: master
        gitApplicationPath: /
        runnerImage: 'alpine/k8s:1.22.15'
        deploy:
            - 'kustomize create --autodetect --recursive --labels=app.kubernetes.io/instance-{{ component.name }}:bns,app.kubernetes.io/part-of:env-{{ env.unique }} --namespace {{ env.k8s.namespace }}'
            - |
                trgt_namespace={{ env.k8s.namespace }}
                # Setup the volume snapshot name and content name
                volume_snapshot_name=vs-{{ env.unique }}
                volume_snapshot_content_name=vsc-{{ env.unique }}
                # Change this to the snapshot id from AWS
                snapshot_handle="snap-a1b2c3d4e51a2b3c4de" #<-- Insert the Snapshot ID here
                # PVC Name
                # Name of Storage class created for ebs csi driver
                storage_class='bns-disk-sc' 
                volume_snapshot_class="ebs-vsc"

                # Apply the updated YAML file
                cat <<EOF > volume-snapshot-content.yaml
                apiVersion: snapshot.storage.k8s.io/v1
                kind: VolumeSnapshotContent
                metadata:
                  annotations:
                    snapshot.storage.kubernetes.io/allow-volume-mode-change: "true"
                  name: $volume_snapshot_content_name
                spec:
                  deletionPolicy: Retain
                  driver: ebs.csi.aws.com
                  source:
                    snapshotHandle: $snapshot_handle
                  volumeSnapshotClassName: $volume_snapshot_class
                  sourceVolumeMode: FileSystem
                  volumeSnapshotRef:
                    kind: VolumeSnapshot
                    name: $volume_snapshot_name
                    namespace: $trgt_namespace
                EOF

                # Generate a volume snapshot in the correct namespace
                cat <<EOF > volume-snapshot.yaml
                apiVersion: snapshot.storage.k8s.io/v1
                kind: VolumeSnapshot
                metadata:
                  name: $volume_snapshot_name
                  namespace: $trgt_namespace
                spec:
                  source:
                    volumeSnapshotContentName: $volume_snapshot_content_name
                  volumeSnapshotClassName: $volume_snapshot_class 
                EOF

                kubectl apply -f volume-snapshot-content.yaml
                kubectl apply -f volume-snapshot.yaml
        destroy:
            - 'kustomize create --autodetect --recursive --namespace {{ env.k8s.namespace }}'
            - |
                # Define the namespace you want to update to
                # Change this to the namespace you wish to deploy on 
                trgt_namespace="{{env.k8s.namespace}}" 
                # Setup the volume snapshot name and content name
                volume_snapshot_name="vs-{{env.unique}}"
                volume_snapshot_content_name="vsc-{{env.unique}}"

                kubectl delete -n $trgt_namespace volumesnapshot $volume_snapshot_name
                kubectl delete volumesnapshotcontent $volume_snapshot_content_name
    -
        kind: KubernetesManifest
        name: fsr-pvc-injector
        gitBranch: master
        gitApplicationPath: /
        runnerImage: 'alpine/k8s:1.22.15'
        deploy:
            - 'kustomize create --autodetect --recursive --labels=app.kubernetes.io/instance-{{ component.name }}:bns,app.kubernetes.io/part-of:env-{{ env.unique }} --namespace {{ env.k8s.namespace }}'
            - |
                # Create PVC for environment Post deploy of DB 
                pvc_name=<VOLUME_NAME>-{{env.unique}} #<--- Replace <VOLUME_NAME> with the volume[].name defined at the bottom of this file
                volume_snapshot_name=vs-{{ env.unique }}
                kubectl scale --replicas=0 deployment <NAME_OF_COMPONENT> -n {{env.k8s.namespace}} # <--- Replace <NAME_OF_COMPONENT> With the name of the component that the pvc is bound to.
                kubectl delete pvc -n {{env.k8s.namespace}} $pvc_name
                cat <<EOF | kubectl apply -f -
                  apiVersion: v1
                  kind: PersistentVolumeClaim
                  metadata:
                    name: $pvc_name
                    namespace: {{env.k8s.namespace}}
                  spec:
                    accessModes:
                      - ReadWriteOnce
                    storageClassName: bns-disk-sc
                    resources:
                      requests:
                        storage: 10Gi  #<-- Make sure you define the size that reflects the snapshots size
                    dataSource:
                      name: $volume_snapshot_name
                      kind: VolumeSnapshot
                      apiGroup: snapshot.storage.k8s.io
                EOF
                kubectl scale --replicas=1 deployment <NAME_OF_COMPONENT> -n {{env.k8s.namespace}}
        destroy:
            - 'kustomize create --autodetect --recursive --namespace {{ env.k8s.namespace }}'
            - 'kubectl scale --replicas=0 deployment <NAME_OF_COMPONENT> -n {{env.k8s.namespace}}' #<--- Replace <NAME_OF_COMPONENT> With the name of the component that the pvc is bound to.
            - 'pvc_name=<VOLUME_NAME>-{{env.unique}}' #<--- Update volume name here
            - 'kubectl delete pvc -n {{env.k8s.namespace}} $pvc_name'
        dependsOn:
            - mysql
    -
        kind: Database
        name: mysql #<--- value of <NAME_OF_COMPONENT>
        dockerCompose:
            image: 'mysql:latest'
            environment:
                MYSQL_PASSWORD: password
                MYSQL_ROOT_PASSWORD: root
                MYSQL_USER: admin
            ports:
                - '3306:3306'
        volumes:
            -
                name: db-data
                mount: /var/lib/mysql
                subPath: ''
        dependsOn:
            - volume-snapshot-generator
volumes:
    -
        name: db-data  #<-- Volume name is here, this will be used as the pvc's name 
        size: 10Gi #<-- Make sure you define the size that reflects the snapshots size
        type: disk

```
